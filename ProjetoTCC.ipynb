{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Definição do problema\n",
    "> O objetivo deste trabalho é apresentar uma análise sobre os preços de produtos importados pelo Brasil, comparando os valores declarados numa operação de importação com os preços praticados no comércio internacional.\n",
    "Para isso, primeiramente, será realizado um levantamento de preços junto ao mercado mundial para um grupo de mercadorias de alto valor agregado.\n",
    "Em seguida, buscar-se-á os preços desses mesmos produtos declarados em processos de importação de mercadorias.\n",
    "Por fim, far-se-á a comparação entre as médias desses valores, visando a uma conclusão quanto a indícios de fraudes - subfaturamento ou superfaturamento - nas operações de importação realizadas pelas empresas brasileiras.\n",
    "\n",
    "### 2. A coleta de dados\n",
    "> Os datasets usados neste trabalho foram coletados de fontes diversas. \n",
    "> O DataCoSupplyChainDataset tem como fonte o site __www.kaggle.com__ \n",
    "\n",
    "__Bold por favor__ <br>\n",
    "_Italico Olha isso_ <br>\n",
    "$ a + bX$ <br>\n",
    "__________ dfjlkaj dlkjf lkajkdj\n",
    "> item \n",
    ">>item2\n",
    ">>>item3\n",
    "- item 1\n",
    "- item 2\n",
    "1. item 1\n",
    "2. item 2 <br>\n",
    "<font color=blue>\"font color=blue\"</font><br>\n",
    "paragrafog <br> outro paragrafo<br>\n",
    "#isto é comentário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "#####Fim definição de páginas\n",
      "\n",
      "\n",
      "\n",
      "#####Fim aquisição de páginas\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Descrição  418 non-null    object\n",
      " 1   Preço      418 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 6.7+ KB\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "#bibliotecas para requisição de páginas dinâmicas\n",
    "from selenium import webdriver \n",
    "from selenium.webdriver.common.keys import Keys \n",
    "import time \n",
    "\n",
    "#Preparando a aquisição das páginas\n",
    "    #Criando informação sobre quem está fazendo o scrap\n",
    "headers = {\n",
    "    'User-Agent': 'João Lima, from PUC-MG University',\n",
    "    'From': 'jbetol@gmail.com'\n",
    "}\n",
    "\n",
    "#Ainda precisa Verificar com Try Except se driver está dispoível\n",
    "driver = webdriver.Firefox('/media/joao/HDLinux/tools')\n",
    "\n",
    "#url = \"https://www.alibaba.com/trade/search?IndexArea=product_en&CatId=5904002&fsb=y&viewtype=&tab=&SearchScene=&SearchText=phone+display+lcd+screen\"\n",
    "\n",
    "#Vamos pegar 11 páginas de dados e jogar num array\n",
    "paginas = []\n",
    "for i in range(1,30):\n",
    "    url = 'https://www.alibaba.com/products/phone_display_lcd_screen/CID5904002.html?spm=a2700.galleryofferlist.0.0.126c1524tZVgH8&IndexArea=product_en&page='+ str(i)\n",
    "    paginas.append(url)\n",
    "\n",
    "print(\"#####Fim definição de páginas\\n\\n\")\n",
    "#Dicionário que vai guardar os dados das páginas in memory\n",
    "desc_items = {} \n",
    "for pagina in paginas:\n",
    "\n",
    "    driver.get(pagina)\n",
    "    time.sleep(1)\n",
    "#Verificar modo silencioso para o geckodriver\n",
    "    req = driver.page_source\n",
    "    soup = BeautifulSoup(req, \"html.parser\")\n",
    "\n",
    "    #Aqui é para páginas estáticas. Não usa o webdriver\n",
    "    #req = requests.get(url)\n",
    "    #soup = BeautifulSoup(req.text, \"html.parser\")\n",
    "\n",
    "    #Adquirindo a lista dos produtos que se encontra na classe indicada\n",
    "    classes = soup.find('div', class_ = \"organic-list app-organic-search__list\")\n",
    "\n",
    "    #Agora vamos buscar os itens da lista\n",
    "    items =  classes.find_all(class_ = 'organic-gallery-offer-outter J-offer-wrapper')\n",
    "\n",
    "    #Para cada item, pegar apenas descrição e o preco e guardar num dicionário\n",
    "    for item in items:\n",
    "        descricao = item.find('h4').get('title')\n",
    "        preco = item.find('p', class_ = 'elements-offer-price-normal').get('title')\n",
    "        desc_items[descricao] = preco \n",
    "\n",
    "#transformando o dicionário em DataFrame do Pandas\n",
    "print(\"\\n#####Fim aquisição de páginas\\n\\n\")\n",
    "\n",
    "df = pd.DataFrame(desc_items.items(), columns=['Descrição','Preço']) \n",
    "df.info()\n",
    "# displaying the DataFrame  \n",
    "#print('DataFrame:\\n', df) \n",
    "\n",
    "# saving the DataFrame as a CSV file \n",
    "gfg_csv_data = df.to_csv('lista.csv', header = True) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}